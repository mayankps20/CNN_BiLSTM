{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "17b497ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0d1bd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "Debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b292d1bd",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e8583a43-1db8-4534-a4b1-2f1b4e02ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, conv_input, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(conv_input, conv_input, 1)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)  # Multiply hidden_size by 2 because it's bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_size\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        # Initialize hidden state and cell state with dimensions accounting for bidirectionality\n",
    "        h0 = torch.randn((self.num_layers * 2, x.shape[0], self.hidden_dim)).to(device)\n",
    "        c0 = torch.randn((self.num_layers * 2, x.shape[0], self.hidden_dim)).to(device)\n",
    "        \n",
    "        output, _ = self.lstm(x, (h0, c0))\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output[:, -1, :]) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e495ca1f-00e4-4d28-b201-e43b1f0289fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\mayank pratap singh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\MAYANK PRATAP SINGH\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "63ef844e-7715-48e1-828f-4ab88cbd4486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "LSTMModel                                [128, 60, 2]              [128, 1]                  --\n",
       "├─Conv1d: 1-1                            [128, 60, 2]              [128, 60, 2]              3,660\n",
       "├─LSTM: 1-2                              [128, 60, 2]              [128, 60, 256]            1,716,224\n",
       "├─Dropout: 1-3                           [128, 60, 256]            [128, 60, 256]            --\n",
       "├─Linear: 1-4                            [128, 256]                [128, 1]                  257\n",
       "===================================================================================================================\n",
       "Total params: 1,720,141\n",
       "Trainable params: 1,720,141\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 13.18\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.06\n",
       "Forward/backward pass size (MB): 15.85\n",
       "Params size (MB): 6.88\n",
       "Estimated Total Size (MB): 22.79\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# Instantiate the model\n",
    "model = LSTMModel(\n",
    "    conv_input=60,   # in_channels for the Conv1d\n",
    "    input_size=2,   \n",
    "    hidden_size=128,\n",
    "    num_layers=5,\n",
    "    output_size=1\n",
    ")\n",
    "summary(model, input_size=(128, 60, 2), col_names=[\"input_size\", \"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb02bb5",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "60fda6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 25C batteries\n",
    "# Create empty lists to store the read DataFrames\n",
    "dataframes_Cap = []\n",
    "dataframes_EIS = []\n",
    "\n",
    "# Use a loop to read files and assign names\n",
    "for i in range(1, 9):\n",
    "    # Construct file names\n",
    "    file_name_cap = f\"Capacity_data/Data_Capacity_25C{i:02}.txt\"\n",
    "    file_name_EIS = f\"EIS_data/EIS_state_V_25C{i:02}.txt\"  # Use State V\n",
    "    \n",
    "    if not os.path.isfile(file_name_cap):\n",
    "        print(f\"Cap file {file_name_cap} does not exist, skipping...\")\n",
    "        continue\n",
    "    elif not os.path.isfile(file_name_EIS):\n",
    "        print(f\"EIS file {file_name_EIS} does not exist, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Read files and add to the list\n",
    "    df_cap = pd.read_csv(file_name_cap, sep=\"\\t\")\n",
    "    df_EIS = pd.read_csv(file_name_EIS, sep=\"\\t\")\n",
    "    \n",
    "    if i == 1 or i == 5:\n",
    "        cap_number = 3\n",
    "    else:\n",
    "        cap_number = 5\n",
    "    \n",
    "    # Exclude underperforming batteries\n",
    "    if i == 4 or i == 8:\n",
    "        continue\n",
    "    cycle = []\n",
    "    cap = []\n",
    "    eis = []\n",
    "    cycle_max = df_cap[df_cap.columns[1]].max()\n",
    "    cycle_max2 = df_EIS[df_EIS.columns[1]].max()\n",
    "    cycle_number = min(cycle_max, cycle_max2)\n",
    "    \n",
    "    for i in range(1, int(cycle_number) + 1):\n",
    "        temp = df_cap[df_cap[df_cap.columns[1]] == i][df_cap.columns[cap_number]][-1:].max()\n",
    "        temp_EIS_Re = np.array(df_EIS[df_EIS[df_EIS.columns[1]] == i][df_EIS.columns[3]][:])\n",
    "        temp_EIS_Im = np.array(df_EIS[df_EIS[df_EIS.columns[1]] == i][df_EIS.columns[4]][:])\n",
    "        cycle.append(i)\n",
    "        cap.append(temp)\n",
    "        eis.append(np.concatenate((temp_EIS_Re, temp_EIS_Im), axis=0))   \n",
    "    dataframes_Cap.append(cap)\n",
    "    dataframes_EIS.append(eis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "28916271-ef58-4597-a485-99ef266b28b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1269, 120) (1269,)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(0, len(dataframes_Cap)):\n",
    "    for j in range(len(dataframes_Cap[i])):\n",
    "        X.append(dataframes_EIS[i][j])\n",
    "        y.append(dataframes_Cap[i][j])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ca5cc114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data at 35C\n",
    "for i in range(1, 3):\n",
    "    # Construct file names\n",
    "    file_name_cap = f\"Capacity_data/Data_Capacity_35C{i:02}.txt\"\n",
    "    file_name_EIS = f\"EIS_data/EIS_state_V_35C{i:02}.txt\"  # Use State V\n",
    "    \n",
    "    # Skip missing files\n",
    "    if not os.path.isfile(file_name_cap):\n",
    "        print(f\"Cap file {file_name_cap} does not exist, skipping...\")\n",
    "        continue\n",
    "    elif not os.path.isfile(file_name_EIS):\n",
    "        print(f\"EIS file {file_name_EIS} does not exist, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Read files and add to the list\n",
    "    df_cap = pd.read_csv(file_name_cap, sep=\"\\t\")\n",
    "    df_EIS = pd.read_csv(file_name_EIS, sep=\"\\t\")\n",
    "    cap_number = 3\n",
    "    \n",
    "    cycle = []\n",
    "    cap = []\n",
    "    eis = []\n",
    "    cycle_max = df_cap[df_cap.columns[1]].max()\n",
    "    cycle_max2 = df_EIS[df_EIS.columns[1]].max()\n",
    "    cycle_number = min(cycle_max, cycle_max2)\n",
    "    \n",
    "    for i in range(1, int(cycle_number) + 1):\n",
    "        temp = df_cap[df_cap[df_cap.columns[1]] == i][df_cap.columns[cap_number]][-1:].max()\n",
    "        temp_EIS_Re = np.array(df_EIS[df_EIS[df_EIS.columns[1]] == i][df_EIS.columns[3]][:])\n",
    "        temp_EIS_Im = np.array(df_EIS[df_EIS[df_EIS.columns[1]] == i][df_EIS.columns[4]][:])\n",
    "        cycle.append(i)\n",
    "        cap.append(temp)\n",
    "        eis.append(np.concatenate((temp_EIS_Re, temp_EIS_Im), axis=0))\n",
    "    dataframes_Cap.append(cap)\n",
    "    dataframes_EIS.append(eis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "06604796-f822-4620-9224-5a008dd1d350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1913, 120) (1913,)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(0, len(dataframes_Cap)):\n",
    "    for j in range(len(dataframes_Cap[i])):\n",
    "        X.append(dataframes_EIS[i][j])\n",
    "        y.append(dataframes_Cap[i][j])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cab4347c-8bd4-4bdc-8a0c-421eb0a0f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data at 45C\n",
    "for i in range(1, 3):\n",
    "    # Construct file names\n",
    "    file_name_cap= f\"Capacity_data/Data_Capacity_45C{i:02}.txt\"\n",
    "    file_name_EIS = f\"EIS_data/EIS_state_V_45C{i:02}.txt\"  # Use State V\n",
    "    \n",
    "    if not os.path.isfile(file_name_cap):\n",
    "        print(f\"Cap file {file_name_cap} does not exist, skipping...\")\n",
    "        continue\n",
    "    elif not os.path.isfile(file_name_EIS):\n",
    "        print(f\"EIS file {file_name_EIS} does not exist, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Read files and add to the list\n",
    "    df_cap = pd.read_csv(file_name_cap, sep=\"\\t\")\n",
    "    df_EIS = pd.read_csv(file_name_EIS, sep=\"\\t\")\n",
    "    # print(df_cap.columns)\n",
    "    cap_number = 3\n",
    "    \n",
    "    cycle = []\n",
    "    cap = []\n",
    "    eis = []\n",
    "    cycle_max = df_cap[df_cap.columns[1]].max()\n",
    "    cycle_max2 = df_EIS[df_EIS.columns[1]].max()\n",
    "    cycle_number = min(cycle_max, cycle_max2)\n",
    "    \n",
    "    for i in range(1, int(cycle_number) + 1):\n",
    "        temp = df_cap[df_cap[df_cap.columns[1]]==i][df_cap.columns[cap_number]][-1:].max()\n",
    "        temp_EIS_Re = np.array(df_EIS[df_EIS[df_EIS.columns[1]]==i][df_EIS.columns[3]][:])\n",
    "        temp_EIS_Im = np.array(df_EIS[df_EIS[df_EIS.columns[1]]==i][df_EIS.columns[4]][:])\n",
    "        # temp = temp/max_scale\n",
    "        cycle.append(i)\n",
    "        cap.append(temp)\n",
    "        eis.append(np.concatenate((temp_EIS_Re, temp_EIS_Im), axis=0))\n",
    "    dataframes_Cap.append(cap)\n",
    "    dataframes_EIS.append(eis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9c112f9f-3333-44d8-8fe8-329c41369b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2522, 120) (2522,)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(0, len(dataframes_Cap)):\n",
    "    for j in range(len(dataframes_Cap[i])):\n",
    "        X.append(dataframes_EIS[i][j])\n",
    "        y.append(dataframes_Cap[i][j])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a52cf99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize each real part and each imaginary part of EIS separately\n",
    "remax = []\n",
    "immax = []\n",
    "data = {}\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Reshape the target variable 'y' and normalize it\n",
    "y = y.reshape(-1,1)\n",
    "y = scaler.fit_transform(y)\n",
    "\n",
    "# Process each battery's data individually for cross-training and validation\n",
    "start = 0\n",
    "for i in range(len(dataframes_Cap)):\n",
    "    feature_name = f'EIS{i+1:02}'\n",
    "    target_name = f'Cap{i+1:02}'\n",
    "    n = len(dataframes_Cap[i])\n",
    "    \n",
    "    # Normalize the real part of the EIS data\n",
    "    X_r = X[start:start+n, :60].copy()  # Extract the real part of the data\n",
    "    X_r_flat = X_r.flatten()\n",
    "    X_r_min = X_r_flat[:60].min()\n",
    "    X_r_max = X_r_flat[:60].max()\n",
    "    remax.append(X_r_flat[:].max() / X_r_max)\n",
    "    normalized_Xr_flat = ((X_r_flat.reshape(-1, 1)) - X_r_min) / (X_r_max - X_r_min)\n",
    "    normalized_Xr_data = normalized_Xr_flat.reshape(X[start:start+n, :60].shape)\n",
    "    \n",
    "    # Normalize the imaginary part of the EIS data\n",
    "    X_i = X[start:start+n, 60:]  # Extract the imaginary part of the data\n",
    "    X_i_flat = X_i.flatten()\n",
    "    X_i_min = X_i_flat[:60].min()\n",
    "    X_i_max = X_i_flat[:60].max()\n",
    "    immax.append(X_i_flat[:].max() / X_i_max)\n",
    "    normalized_Xi_flat = ((X_i_flat.reshape(-1, 1)) - X_i_min) / (X_i_max - X_i_min)\n",
    "    normalized_Xi_data = normalized_Xi_flat.reshape(X[start:start+n, 60:].shape)\n",
    "    \n",
    "    # Combine the normalized real and imaginary parts\n",
    "    data[feature_name] = np.concatenate((normalized_Xr_data, normalized_Xi_data), axis=1)\n",
    "    \n",
    "    # Reshape the data into (batch, 60, 2) format, where real and imaginary parts are treated as a single feature\n",
    "    data[feature_name] = data[feature_name].reshape(-1, 2, 60)\n",
    "    data[feature_name] = data[feature_name].transpose(0, 2, 1)\n",
    "    \n",
    "    # Store the corresponding capacity values\n",
    "    data[target_name] = y[start:start+n].reshape(-1, 1)\n",
    "    start += n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "79c87f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training data from multiple EIS datasets, excluding certain datasets because we are using them for testing purpose\n",
    "start = 0\n",
    "for i in range(1, 11):\n",
    "    if i == 1:\n",
    "        trainning_data = data[f\"EIS{i:02}\"][start:].copy()\n",
    "        trainning_target = data[f\"Cap{i:02}\"][start:].copy()\n",
    "    elif i != 4 and i != 8 and i != 10:  # Exclude datasets 4, 8, and 10 from training\n",
    "        trainning_data = np.vstack((trainning_data, data[f\"EIS{i:02}\"][start:]))\n",
    "        trainning_target = np.vstack((trainning_target, data[f\"Cap{i:02}\"][start:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "052e3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training data and targets to PyTorch tensors\n",
    "trainning_data = torch.tensor(trainning_data, dtype=torch.float32)\n",
    "trainning_target = torch.tensor(trainning_target, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8e62bdf7-ae74-40f2-b380-79f7209ee150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: torch.Size([1619, 60, 2])\n",
      "Training Target Shape: torch.Size([1619, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Shape:\", trainning_data.shape)\n",
    "print(\"Training Target Shape:\", trainning_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184247ef",
   "metadata": {},
   "source": [
    "### Train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52159092-d0b9-435a-a782-7c01fe6fad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "\n",
    "#Train Process\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = 2  # Number of features\n",
    "hidden_size = 128\n",
    "num_layers = 5\n",
    "output_size = 1\n",
    "conv_input = 60\n",
    "batch_size = 128\n",
    "epochs = 1500\n",
    "n_splits = 5\n",
    "from sklearn.model_selection import KFold  \n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "model_number = 0\n",
    "for train_idx, val_idx in kf.split(trainning_data):  \n",
    "    train_X, val_X = trainning_data[train_idx], trainning_data[val_idx]  \n",
    "    train_y, val_y = trainning_target[train_idx], trainning_target[val_idx]  \n",
    "    train_dataset = TensorDataset(train_X, train_y)  \n",
    "    val_dataset = TensorDataset(val_X, val_y)  \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  \n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  \n",
    "    model = LSTMModel(conv_input, input_size, hidden_size, num_layers, output_size) \n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()   \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001,betas=(0.5,0.999))  \n",
    "     \n",
    "    for epoch in range(epochs):\n",
    "        model.train() \n",
    "        for i, (inputs, labels) in enumerate(train_loader):  \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()  \n",
    "            outputs = model(inputs)  \n",
    "            loss = criterion(outputs, labels)  \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)  \n",
    "                val_loss = criterion(outputs, labels)    \n",
    "        if epoch%100 ==0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}, Validation Loss: {val_loss.item()}') \n",
    "    torch.save(model.state_dict(), f\"model_weights/CNNBiLSTM/test{model_number}.pth\")\n",
    "    model_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88168a3-cd23-4f0f-95ef-bb504eee8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Titles for each plot\n",
    "titles = ['25C01', '25C02', '25C03', '25C05', '25C06', '25C07', '35C01', '35C02', '45C01', '45C02']\n",
    "\n",
    "ID = 1  # Tracking dataset indexing\n",
    "title_idx = 0  # Title list index\n",
    "start = 0\n",
    "mean_RMSE_train = 0\n",
    "mean_R2_train = 0\n",
    "\n",
    "# Initialize model\n",
    "model = LSTMModel(conv_input, input_size, hidden_size, num_layers, output_size)\n",
    "model = model.to(device)\n",
    "\n",
    "# Create directories if they don't exist\n",
    "data_dir = \"data\"\n",
    "figure_dir = \"figure_results\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(figure_dir, exist_ok=True)\n",
    "\n",
    "# Create 3x4 subplot grid\n",
    "fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(15, 8))\n",
    "\n",
    "# Loop through plots\n",
    "for i in range(3):  \n",
    "    for j in range(4):\n",
    "        if title_idx < len(titles):  # Ensure we don't go out of bounds\n",
    "            result = []\n",
    "            attention_all = []  # Store attention weights for interpretability\n",
    "            x = torch.tensor(data[f\"EIS{ID:02}\"], dtype=torch.float32)\n",
    "\n",
    "            # Predict using multiple trained models (cross-validation)\n",
    "            for k in range(n_splits):\n",
    "                model.load_state_dict(torch.load(f\"model_weights/CNNBiLSTM_Attention/test{k}.pth\",\n",
    "                                                  map_location=torch.device(device)))\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(x.to(device))\n",
    "                    \n",
    "                    # Handle case where attention weights are returned\n",
    "                    if isinstance(outputs, tuple):\n",
    "                        outputs, attention_weights = outputs\n",
    "                        attention_all.append(attention_weights.cpu().detach().numpy())  # Store attention maps\n",
    "                    else:\n",
    "                        attention_weights = None  # Avoids error if model does not return attention\n",
    "                    \n",
    "                    outputs = outputs.cpu().detach().numpy()\n",
    "                    outputs = scaler.inverse_transform(outputs)\n",
    "                    result.append(outputs)\n",
    "\n",
    "            # Aggregate results across folds and ensure 1D shape\n",
    "            result = np.array(result)\n",
    "            out = np.mean(result, axis=0).squeeze()  # Convert to 1D\n",
    "            out_upper = np.max(result, axis=0).squeeze()\n",
    "            out_lower = np.min(result, axis=0).squeeze()\n",
    "\n",
    "            # Get true values and inverse transform\n",
    "            true = np.array(data[f\"Cap{ID:02}\"]).reshape(-1, 1)  # Ensure shape\n",
    "            true = scaler.inverse_transform(true).squeeze()  # Convert to 1D\n",
    "\n",
    "            # Compute evaluation metrics\n",
    "            MSE = mean_squared_error(out[start:], true[start:])\n",
    "            R2_result = r2_score(true[start:], out[start:])\n",
    "            RMSE_result = math.sqrt(MSE)\n",
    "            mean_RMSE_train += RMSE_result\n",
    "            mean_R2_train += R2_result\n",
    "\n",
    "            # Format RMSE and R² values for display\n",
    "            RMSE_str = \"{:.4f}\".format(RMSE_result)\n",
    "            R2_str = \"{:.4f}\".format(R2_result)\n",
    "\n",
    "            # X-axis values for plotting\n",
    "            x_vals = np.linspace(0, x.shape[0], x.shape[0])\n",
    "\n",
    "            # **Plot true vs predicted capacity using default Matplotlib colors**\n",
    "            axs[i, j].plot(x_vals[start:], true[start:], label=\"True Capacity\")  # Uses Matplotlib default (Blue)\n",
    "            axs[i, j].plot(x_vals[start:], out[start:], label=\"Predicted Capacity\")  # Uses Matplotlib default (Orange)\n",
    "            axs[i, j].fill_between(x_vals[start:], out_upper[start:], out_lower[start:], color='orange', alpha=0.5)  # Shaded region\n",
    "\n",
    "            axs[i, j].set_title(titles[title_idx])\n",
    "            axs[i, j].text(0.95, 0.95, f\"RMSE: {RMSE_str}\", ha='right', va='top', fontsize=12, transform=axs[i, j].transAxes)\n",
    "            axs[i, j].text(0.95, 0.85, f\"R2: {R2_str}\", ha='right', va='top', fontsize=12, transform=axs[i, j].transAxes)\n",
    "            axs[i, j].legend(loc='lower left', fontsize='small')\n",
    "            axs[i, j].grid(True)\n",
    "\n",
    "            # Save predictions\n",
    "            with open(f\"{data_dir}/Nature_Cap_train_{titles[title_idx]}.txt\", 'w') as file:\n",
    "                for item in range(out[start:].shape[0]):\n",
    "                    out_number = round(float(out[start:][item].flatten()), 4)\n",
    "                    file.write(str(out_number) + '\\n')\n",
    "\n",
    "            # Save averaged attention weights (for interpretability)\n",
    "            if attention_weights is not None:\n",
    "                np.save(f\"{data_dir}/Attention_Weights_{titles[title_idx]}.npy\", np.mean(np.array(attention_all), axis=0))\n",
    "\n",
    "            # Increment dataset ID and title index\n",
    "            ID += 1\n",
    "            title_idx += 1\n",
    "\n",
    "            # Break condition to avoid errors\n",
    "            if ID == 11:\n",
    "                break\n",
    "\n",
    "# Adjust subplot spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save final figure\n",
    "plt.savefig(f'{figure_dir}/cap_alltempalldata_test_5_10_12_attention.png')\n",
    "\n",
    "# Print overall metrics\n",
    "print(\"train RMSE: \", mean_RMSE_train / len(titles))\n",
    "print(\"train R2: \", mean_R2_train / len(titles))\n",
    "\n",
    "# Show final visualization\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
